# src/train.py

"""
í•™ìŠµ ë° í‰ê°€ ìŠ¤í¬ë¦½íŠ¸

- train_epoch: ë‹¨ì¼ ì—í­ ë™ì•ˆ ëª¨ë¸ì„ í•™ìŠµ
- evaluate: ëª¨ë¸ì„ í‰ê°€í•˜ì—¬ Recall@K ë° NDCG@K ê³„ì‚°
"""

import torch
from tqdm import tqdm
import numpy as np
from src.utils.metrics import Recall, NDCG, MRR, Precision

def train_epoch(model, dataloader, optimizer, device, beta):
    """
    ë‹¨ì¼ ì—í­ ë™ì•ˆ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” í•¨ìˆ˜ (BPR Loss + L2 ì •ê·œí™”)
    
    Args:
        - model (torch.nn.Module): í•™ìŠµí•  ëª¨ë¸
        - dataloader (torch.utils.data.DataLoader): í•™ìŠµ ë°ì´í„°ë¡œë”
        - optimizer (torch.optim.Optimizer): ìµœì í™” ì•Œê³ ë¦¬ì¦˜
        - device (str): "cuda" ë˜ëŠ” "cpu"
        - beta (float): L2 ì •ê·œí™” ì •ë„
        
    Returns:
        - (float): ì—í­ ë™ì•ˆì˜ í‰ê·  ì†ì‹¤ ê°’
    """
    model.train() # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •
    epoch_loss = 0.0
    num_batches = len(dataloader)
    
    # progress bar ì„¤ì •
    progress = tqdm(dataloader, desc="Training ğŸ‹ï¸â€â™‚ï¸", leave=False)
    
    for batch in progress:
        # ë°°ì¹˜ ë°ì´í„° 
        user = batch["user"].squeeze().to(device)         # shape: (batch_size,)
        pos_item = batch["pos_item"].squeeze().to(device) # shape: (batch_size,)
        neg_item = batch["neg_item"].squeeze().to(device) # shape: (batch_size, neg_size)
        
        optimizer.zero_grad() # ì˜µí‹°ë§ˆì´ì €ì˜ ê¸°ìš¸ê¸° ì´ˆê¸°í™”
        
        # ê¸ì • ìƒ˜í”Œ ì ìˆ˜ ì˜ˆì¸¡
        pos_scores = model(user, pos_item) # shape: (batch_size,)
        # ë¶€ì • ìƒ˜í”Œ ì ìˆ˜ ì˜ˆì¸¡
        neg_scores = model(user, neg_item) # shape: (batch_size, neg_size)
        neg_scores = neg_scores.mean(dim=1)  # shape: (batch_size,)
        
        # BPR Loss ê³„ì‚°: -log(sigmoid(pos - neg))
        loss = -torch.mean(torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-8))
        # L2 ì •ê·œí™” ê³„ì‚°: ëª¨ë“  íŒŒë¼ë¯¸í„°ì˜ ì œê³±í•©
        l2_reg = 0.0
        for param in model.parameters():
            l2_reg += torch.sum(param ** 2)
        loss += beta * l2_reg # ì •ê·œí™” í•­ ì¶”ê°€
        
        # ì—­ì „íŒŒ ë° ìµœì í™”
        loss.backward()
        optimizer.step()

        epoch_loss += loss.item()
        progress.set_postfix(loss=loss.item())  # í˜„ì¬ ë°°ì¹˜ì˜ ì†ì‹¤ í‘œì‹œ

    average_loss = epoch_loss / num_batches
    return average_loss
    
def evaluate(model, dataloader, device, topk=10):
    """
    ëª¨ë¸ì„ í‰ê°€í•˜ì—¬ Recall@K, Precision@K, NDCG@K, MRR@K ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜

    Args:
        model (torch.nn.Module): í‰ê°€í•  ëª¨ë¸
        dataloader (torch.utils.data.DataLoader): í‰ê°€ ë°ì´í„°ë¡œë”
        device (str): "cuda" ë˜ëŠ” "cpu"
        k (int): ìƒìœ„ kê°œì˜ ì¶”ì²œì„ ê³ ë ¤
    
    Returns:
        dict: {'Recall@K': value, 'Precision@K': value, 'NDCG@K': value, 'MRR@K': value}
    """
    model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
    
    # ë©”íŠ¸ë¦­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    recall_metric = Recall(topk)
    precision_metric = Precision(topk)
    ndcg_metric = NDCG(topk)
    mrr_metric = MRR(topk)
    
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Evaluating ğŸ“Š", leave=False):
            user = batch['user'].squeeze().to(device)          # shape: (batch_size,)
            pos_item = batch['pos_item'].squeeze().to(device)  # shape: (batch_size,)
            neg_item = batch['neg_item'].squeeze().to(device)  # shape: (batch_size, neg_size)

            # ê¸ì • ìƒ˜í”Œ ì ìˆ˜ ì˜ˆì¸¡
            pos_scores = model(user, pos_item)  # shape: (batch_size,)

            # ë¶€ì • ìƒ˜í”Œ ì ìˆ˜ ì˜ˆì¸¡
            neg_scores = model(user, neg_item)  # shape: (batch_size, neg_size)
            neg_scores = neg_scores.mean(dim=1)  # shape: (batch_size,)
            
            # ì ìˆ˜ ì°¨ì´ ê³„ì‚°
            score_diff = pos_scores - neg_scores  # shape: (batch_size,)

            # ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ ì ìš©í•˜ì—¬ í™•ë¥ ë¡œ ë³€í™˜
            probs = torch.sigmoid(score_diff)  # shape: (batch_size,)